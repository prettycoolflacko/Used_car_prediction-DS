{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc768a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35392fb",
   "metadata": {},
   "source": [
    "# Used Car Price Prediction in America\n",
    "**Objective:** Predict used car market prices using Random Forest Regressor and analyze factors affecting price\n",
    "\n",
    "**Methods:**\n",
    "- Data Preprocessing (duplicates, missing values, outliers)\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Feature Engineering\n",
    "- Random Forest Regressor Model\n",
    "- Evaluation Metrics: R¬≤ Score, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce51527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 852,122 rows, 8 columns\n",
      "   Price  Year  Mileage              City State                Vin   Make  \\\n",
      "0   8995  2014    35725           El Paso    TX  19VDE2E53EE000083  Acura   \n",
      "1  10888  2013    19606  Long Island City    NY  19VDE1F52DE012636  Acura   \n",
      "2   8995  2013    48851           El Paso    TX  19VDE2E52DE000025  Acura   \n",
      "3  10999  2014    39922           Windsor    CO  19VDE1F71EE003817  Acura   \n",
      "4  14799  2016    22142            Lindon    UT  19UDE2F32GA001284  Acura   \n",
      "\n",
      "          Model  \n",
      "0    ILX6-Speed  \n",
      "1    ILX5-Speed  \n",
      "2    ILX6-Speed  \n",
      "3    ILX5-Speed  \n",
      "4  ILXAutomatic  \n",
      "Year range: 1997 - 2018\n",
      "Mileage range: 5 - 2856196\n",
      "Price range: 1500 - 499500\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"true_car_listings.csv\")\n",
    "print(f\"Dataset loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"Year range: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "print(f\"Mileage range: {df['Mileage'].min()} - {df['Mileage'].max()}\")\n",
    "print(f\"Price range: {df['Price'].min()} - {df['Price'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce385ef",
   "metadata": {},
   "source": [
    "## Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Overview\n",
    "print(\"=== DATA INFO ===\")\n",
    "df.info()\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b81bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Missing Values & Duplicates\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nDuplicates: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d27241",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original dataset: {df.shape[0]:,} rows\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"After removing duplicates: {df_clean.shape[0]:,} rows\")\n",
    "print(f\"Duplicates removed: {df.shape[0] - df_clean.shape[0]:,}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_count = df_clean.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing values found: {missing_count}\")\n",
    "    df_clean = df_clean.dropna()\n",
    "    print(f\"After removing missing values: {df_clean.shape[0]:,} rows\")\n",
    "else:\n",
    "    print(f\"‚úì No missing values found\")\n",
    "\n",
    "# Reset index\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "print(f\"\\n‚úì Clean dataset: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ca4b5",
   "metadata": {},
   "source": [
    "### 2.1 Data Quality Analysis: Model Feature\n",
    "\n",
    "**Tujuan:** Mengidentifikasi masalah kualitas data pada kolom Model sebelum feature engineering\n",
    "\n",
    "**Proses:**\n",
    "- Deteksi nama model yang bermasalah (terlalu pendek, ambigu, mengandung karakter khusus)\n",
    "- Analisis fragmentasi data (terlalu banyak kategori unik)\n",
    "- Evaluasi konsistensi format nama model\n",
    "- Keputusan untuk tidak menggunakan Model sebagai feature dalam model final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fa876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENHANCED DATA CLEANING: Remove Problematic Model Names ---\n",
    "print(\"=== ENHANCED DATA QUALITY ANALYSIS & CLEANING ===\\n\")\n",
    "\n",
    "total_before = len(df_clean)\n",
    "\n",
    "# 1. Identify ALL types of problematic models\n",
    "has_asterisk = df_clean['Model'].str.contains('\\*', na=False, regex=False)\n",
    "is_too_short = df_clean['Model'].str.len() <= 2  # Single digit/letter models like \"3\", \"X\", \"S\"\n",
    "is_numeric_only = df_clean['Model'].str.match(r'^\\d+$', na=False)  # Pure numbers like \"3\", \"5\", \"350\"\n",
    "\n",
    "problematic = has_asterisk | is_too_short | is_numeric_only\n",
    "problematic_count = problematic.sum()\n",
    "\n",
    "print(f\"üìä INITIAL DATA: {total_before:,} rows\")\n",
    "print(f\"   Unique model names: {df_clean['Model'].nunique():,}\")\n",
    "print(f\"\\n‚ùå DATA QUALITY ISSUES DETECTED:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   Models with '*' (promotional text): {has_asterisk.sum():,} ({(has_asterisk.sum()/total_before*100):.1f}%)\")\n",
    "print(f\"   Models too short (‚â§2 chars):        {is_too_short.sum():,} ({(is_too_short.sum()/total_before*100):.1f}%)\")\n",
    "print(f\"   Models numeric only:                {is_numeric_only.sum():,} ({(is_numeric_only.sum()/total_before*100):.1f}%)\")\n",
    "print(f\"   TOTAL PROBLEMATIC:                  {problematic_count:,} ({(problematic_count/total_before*100):.1f}%)\")\n",
    "\n",
    "# 2. Show examples of problematic models\n",
    "if has_asterisk.sum() > 0:\n",
    "    print(\"\\n1. MODELS WITH ASTERISKS (promotional/listing details):\")\n",
    "    print(\"-\" * 80)\n",
    "    for _, row in df_clean[has_asterisk].head(3).iterrows():\n",
    "        print(f\"   Make: {row['Make']:15s} | Model: {row['Model'][:70]}\")\n",
    "\n",
    "if is_too_short.sum() > 0:\n",
    "    print(\"\\n2. INCOMPLETE MODEL NAMES (‚â§2 characters):\")\n",
    "    print(\"-\" * 80)\n",
    "    examples = df_clean[is_too_short][['Make', 'Model', 'Price']].drop_duplicates('Model').head(10)\n",
    "    for _, row in examples.iterrows():\n",
    "        print(f\"   Make: {row['Make']:15s} | Model: '{row['Model']:5s}' | Price: ${row['Price']:,}\")\n",
    "    print(f\"   ‚ö†Ô∏è  These are truncated (e.g., '3' could be Mazda 3, BMW 3 Series, or Tesla Model 3)\")\n",
    "\n",
    "if is_numeric_only.sum() > 0:\n",
    "    print(\"\\n3. NUMERIC-ONLY MODELS (ambiguous):\")\n",
    "    print(\"-\" * 80)\n",
    "    examples = df_clean[is_numeric_only][['Make', 'Model', 'Price']].drop_duplicates('Model').head(8)\n",
    "    for _, row in examples.iterrows():\n",
    "        print(f\"   Make: {row['Make']:15s} | Model: '{row['Model']:8s}' | Price: ${row['Price']:,}\")\n",
    "\n",
    "# 3. Show clean model examples for comparison\n",
    "print(\"\\n4. CLEAN MODEL EXAMPLES (for comparison):\")\n",
    "print(\"-\" * 80)\n",
    "clean_examples = df_clean[~problematic][['Make', 'Model']].drop_duplicates().head(10)\n",
    "for _, row in clean_examples.iterrows():\n",
    "    print(f\"   Make: {row['Make']:15s} | Model: {row['Model']}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f59382",
   "metadata": {},
   "source": [
    "### üîç Kesimpulan: Mengapa Fitur Model Tidak Digunakan\n",
    "\n",
    "**Hasil Diagnosis:** 2,678 nama model unik dengan berbagai masalah kualitas\n",
    "\n",
    "**Masalah Utama:**\n",
    "\n",
    "1. **Terlalu Terfragmentasi** - 2,678 kategori terlalu banyak, sebagian besar model jarang muncul (frekuensi minimum: 0.000001)\n",
    "\n",
    "2. **Format Tidak Konsisten** - Mobil yang sama memiliki berbagai format: `ILX6-Speed`, `ILX5-Speed`, `ILXAutomatic`\n",
    "\n",
    "3. **Nama Ambigu** - `Grand` bisa Cherokee, Caravan, atau Prix; `Super` bisa Duty atau Cab\n",
    "\n",
    "4. **Overfitting** - Model_Frequency: 34% importance tapi korelasi hanya 0.08 (rasio 4.20x = overfitting ke noise)\n",
    "\n",
    "**Alasan Tidak Digunakan:**\n",
    "- **Make (merek)** sudah menangkap informasi harga: Ferrari > Ford\n",
    "- Populer ‚â† Mahal (Honda Civic: umum tapi terjangkau)\n",
    "- Langka ‚â† Mahal (Model Saturn: langka tapi murah)\n",
    "- Terlalu banyak kategori menyebabkan overfitting\n",
    "\n",
    "**Keputusan:** Gunakan Mileage, Car_Age, Make_Encoded, State_Encoded ‚Üí R¬≤ 87-89%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62435ae",
   "metadata": {},
   "source": [
    "### 3.1 Outlier Detection\n",
    "\n",
    "**Metode:** Interquartile Range (IQR)\n",
    "- Mendeteksi outliers pada kolom Price menggunakan IQR\n",
    "- **Keputusan:** Mempertahankan outliers karena merepresentasikan mobil luxury yang sah di pasar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcc92a",
   "metadata": {},
   "source": [
    "### 3.2 Feature Engineering\n",
    "\n",
    "**Fitur yang Dibuat:**\n",
    "\n",
    "1. **Car_Age** = 2025 - Year\n",
    "   - Lebih intuitif daripada Year untuk prediksi harga\n",
    "   - Mobil lebih tua ‚Üí Harga lebih rendah\n",
    "\n",
    "2. **Make_Encoded** (LabelEncoder)\n",
    "   - Mengubah merek mobil (categorical) menjadi numerik\n",
    "   - Contoh: Ferrari=13, Ford=49, dll.\n",
    "\n",
    "3. **State_Encoded** (LabelEncoder)\n",
    "   - Mengubah lokasi negara bagian menjadi numerik\n",
    "   - Menangkap perbedaan harga regional\n",
    "\n",
    "**Catatan:** Model_Frequency tidak dibuat karena analisis kualitas data di atas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482326d1",
   "metadata": {},
   "source": [
    "### 3.3 Correlation Analysis\n",
    "\n",
    "**Analisis korelasi untuk memahami:**\n",
    "- Fitur mana yang paling berpengaruh terhadap Price\n",
    "- Hubungan antar fitur (multicollinearity)\n",
    "- Arah hubungan (positif/negatif)\n",
    "\n",
    "**Interpretasi:**\n",
    "- **Car_Age vs Price:** Korelasi negatif (mobil lebih tua = harga lebih rendah)\n",
    "- **Mileage vs Price:** Korelasi negatif (mileage tinggi = harga lebih rendah)\n",
    "- **Make_Encoded:** Korelasi rendah (expected untuk categorical encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822de361",
   "metadata": {},
   "source": [
    "### 3.4 Distribution Analysis\n",
    "\n",
    "**Statistik Deskriptif:**\n",
    "- Mean, Median, Standard Deviation\n",
    "- Skewness (kemencengan distribusi)\n",
    "\n",
    "**Visualisasi:**\n",
    "- Histogram untuk melihat bentuk distribusi\n",
    "- Identifikasi apakah data normal, skewed, atau bimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c85e874",
   "metadata": {},
   "source": [
    "### 3.5 Relationship Analysis\n",
    "\n",
    "**Scatter Plot Analysis:**\n",
    "- Visualisasi hubungan antara Car_Age dengan Price\n",
    "- Visualisasi hubungan antara Mileage dengan Price\n",
    "- Visualisasi hubungan Car_Age vs Mileage dengan warna berdasarkan Price\n",
    "\n",
    "**Insight:**\n",
    "- Semakin tua mobil, semakin rendah harganya\n",
    "- Semakin tinggi mileage, semakin rendah harganya\n",
    "- Kombinasi keduanya memberikan prediksi harga yang lebih akurat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ccee89",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "\n",
    "\n",
    "**Tujuan EDA:**- Memvisualisasikan hubungan antara fitur dengan harga\n",
    "\n",
    "- Memahami distribusi data harga, tahun, dan mileage- Menganalisis korelasi antar variabel\n",
    "- Mengidentifikasi outliers dan menentukan apakah perlu dihapus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d00981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection & Visualization for Price\n",
    "print(\"=== OUTLIER DETECTION FOR PRICE ===\\n\")\n",
    "\n",
    "# Calculate IQR\n",
    "Q1 = df_clean['Price'].quantile(0.25)\n",
    "Q3 = df_clean['Price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_clean[(df_clean['Price'] < lower_bound) | (df_clean['Price'] > upper_bound)]\n",
    "\n",
    "print(f\"Q1 (25th percentile): ${Q1:,.2f}\")\n",
    "print(f\"Q3 (75th percentile): ${Q3:,.2f}\")\n",
    "print(f\"IQR: ${IQR:,.2f}\")\n",
    "print(f\"Lower bound: ${lower_bound:,.2f}\")\n",
    "print(f\"Upper bound: ${upper_bound:,.2f}\")\n",
    "print(f\"\\nOutliers detected: {len(outliers)} ({len(outliers)/len(df_clean)*100:.2f}%)\")\n",
    "print(f\"Outlier price range: ${outliers['Price'].min():,.2f} - ${outliers['Price'].max():,.2f}\")\n",
    "print(f\"\\n‚úì Decision: Keep outliers (legitimate luxury cars in market)\")\n",
    "\n",
    "# Boxplot Visualization\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df_clean['Price'], color='purple')\n",
    "plt.title('Price Distribution with Outliers', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Price ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.text(0.02, 0.98, f'Outliers: {len(outliers)} ({len(outliers)/len(df_clean)*100:.1f}%)',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.9), fontsize=10)\n",
    "\n",
    "# Histogram with Outlier Boundaries\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_clean['Price'], bins=50, color='purple', alpha=0.7, edgecolor='black')\n",
    "plt.axvline(lower_bound, color='red', linestyle='--', linewidth=2, label=f'Lower: ${lower_bound:,.0f}')\n",
    "plt.axvline(upper_bound, color='red', linestyle='--', linewidth=2, label=f'Upper: ${upper_bound:,.0f}')\n",
    "plt.title('Price Distribution with Boundaries', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Price ($)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66996a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Create and encode features\n",
    "print(\"=== FEATURE ENGINEERING ===\\n\")\n",
    "\n",
    "# Create Car_Age feature (more interpretable than Year)\n",
    "df_clean['Car_Age'] = 2025 - df_clean['Year']\n",
    "print(f\"Created Car_Age feature (Range: {df_clean['Car_Age'].min()}-{df_clean['Car_Age'].max()} years)\")\n",
    "\n",
    "# Encode categorical features\n",
    "le_make = LabelEncoder()\n",
    "le_state = LabelEncoder()\n",
    "\n",
    "df_clean['Make_Encoded'] = le_make.fit_transform(df_clean['Make'])\n",
    "df_clean['State_Encoded'] = le_state.fit_transform(df_clean['State'])\n",
    "\n",
    "print(f\"Encoded {df_clean['Make'].nunique()} car makes (brands)\")\n",
    "print(f\"Encoded {df_clean['State'].nunique()} US states\")\n",
    "\n",
    "# Model frequency encoding (captures model popularity)\n",
    "# model_freq = df_clean['Model'].value_counts(normalize=True)\n",
    "# df_clean['Model_Frequency'] = df_clean['Model'].map(model_freq)\n",
    "print(f\"Created Model_Frequency feature (popularity score)\")\n",
    "\n",
    "print(f\"\\nTotal features created: 4\")\n",
    "print(f\"Dataset ready for modeling: {df_clean.shape[0]:,} rows √ó {df_clean.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717155d",
   "metadata": {},
   "source": [
    "### 4.2 Comparison Analysis\n",
    "\n",
    "**Membandingkan performa kedua model:**\n",
    "- Improvement dalam R¬≤ Score\n",
    "- Improvement dalam MAE (pengurangan error)\n",
    "- Improvement dalam RMSE\n",
    "\n",
    "**Keputusan:** Model mana yang lebih baik untuk production?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfe1f2",
   "metadata": {},
   "source": [
    "### 4.3 Visual Comparison\n",
    "\n",
    "**Bar Chart:** Membandingkan metrics kedua model side-by-side\n",
    "**Scatter Plot:** Actual vs Predicted prices untuk melihat seberapa akurat prediksi\n",
    "- Garis merah = Perfect prediction\n",
    "- Semakin dekat titik ke garis merah = semakin akurat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "# First heatmap - All features\n",
    "numerical_cols = ['Price', 'Mileage', 'Car_Age', 'Make_Encoded', 'State_Encoded']\n",
    "correlation = df_clean[numerical_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True, \n",
    "            square=True, linewidths=0.5, ax=axes[0])\n",
    "axes[0].set_title('Correlation Heatmap - All Features', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Second heatmap - Price, Car_Age, Mileage\n",
    "numerical_cols2 = ['Price', 'Car_Age', 'Mileage']\n",
    "correlation2 = df_clean[numerical_cols2].corr()\n",
    "sns.heatmap(correlation2, annot=True, fmt=\".2f\", cmap='viridis', cbar=True, \n",
    "            square=True, linewidths=0.5, ax=axes[1])\n",
    "axes[1].set_title('Correlation Heatmap - Price, Car_Age, Mileage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048a270",
   "metadata": {},
   "source": [
    "### 5.2 Final Model Training\n",
    "\n",
    "**Hyperparameters:**\n",
    "- n_estimators = 100 (jumlah decision trees)\n",
    "- max_depth = 20 (kedalaman maksimum tree untuk mencegah overfitting)\n",
    "- random_state = 42 (reproducibility)\n",
    "- n_jobs = -1 (gunakan semua CPU cores)\n",
    "\n",
    "**Split Data:** 80% training, 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Analysis of Key Features\n",
    "print(\"=== DISTRIBUTION STATISTICS ===\")\n",
    "for col in ['Price', 'Year', 'Mileage']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {df_clean[col].mean():,.2f}\")\n",
    "    print(f\"  Median: {df_clean[col].median():,.2f}\")\n",
    "    print(f\"  Std Dev: {df_clean[col].std():,.2f}\")\n",
    "    print(f\"  Skewness: {df_clean[col].skew():.3f}\")\n",
    "\n",
    "# Price Distribution\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df_clean['Price'], bins=50, edgecolor='black', color='purple', alpha=0.7)\n",
    "plt.title('Price Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Price ($)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.axvline(df_clean['Price'].mean(), color='red', linestyle='--', \n",
    "            linewidth=2, label=f\"Mean: ${df_clean['Price'].mean():,.0f}\")\n",
    "plt.axvline(df_clean['Price'].median(), color='green', linestyle='--', \n",
    "            linewidth=2, label=f\"Median: ${df_clean['Price'].median():,.0f}\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Year Distribution\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(df_clean['Year'], bins=30, edgecolor='black', color='purple', alpha=0.7)\n",
    "plt.title('Year Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mileage Distribution\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(df_clean['Mileage'], bins=50, edgecolor='black', color='purple', alpha=0.7)\n",
    "plt.title('Mileage Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Mileage (miles)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb513d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship Analysis: Factors Affecting Price\n",
    "print(\"=== FACTOR ANALYSIS ===\")\n",
    "\n",
    "# Calculate correlations\n",
    "corr_year = df_clean[['Car_Age', 'Price']].corr().iloc[0, 1]\n",
    "corr_mileage = df_clean[['Mileage', 'Price']].corr().iloc[0, 1]\n",
    "\n",
    "print(f\"Newer cars (higher year) tend to have HIGHER prices\")\n",
    "print(f\"Higher mileage correlates with LOWER prices\")\n",
    "print(f\"Car Age has {abs(corr_year):.1%} correlation with price\")\n",
    "print(f\"Mileage has {abs(corr_mileage):.1%} correlation with price\")\n",
    "\n",
    "# Car Age vs Price\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(df_clean['Car_Age'], df_clean['Price'], alpha=0.4, color='purple', s=10)\n",
    "plt.title('Car Age vs Price', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Car Age', fontsize=12)\n",
    "plt.ylabel('Price ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr_year:.3f}', \n",
    "         transform=plt.gca().transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Mileage vs Price\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(df_clean['Mileage'], df_clean['Price'], alpha=0.4, color='purple', s=10)\n",
    "plt.title('Mileage vs Price', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Mileage (miles)', fontsize=12)\n",
    "plt.ylabel('Price ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.text(0.05, 0.95, f'Correlation: {corr_mileage:.3f}', \n",
    "         transform=plt.gca().transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Car Age vs Mileage (colored by Price)\n",
    "plt.subplot(1, 3, 3)\n",
    "scatter = plt.scatter(df_clean['Car_Age'], df_clean['Mileage'], \n",
    "                     c=df_clean['Price'], alpha=0.5, s=15, cmap='viridis')\n",
    "plt.title('Car Age vs Mileage (colored Price)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Car Age', fontsize=12)\n",
    "plt.ylabel('Mileage (miles)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Price ($)', rotation=270, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7a78c",
   "metadata": {},
   "source": [
    "### 6.2 Feature Importance Analysis\n",
    "\n",
    "**Feature Importance menunjukkan:**\n",
    "- Seberapa penting setiap fitur dalam membuat prediksi\n",
    "- Fitur dengan importance tinggi = lebih sering digunakan untuk split dalam decision trees\n",
    "- Membantu memahami faktor utama yang mempengaruhi harga mobil\n",
    "\n",
    "**Interpretasi:**\n",
    "- Mileage dan Car_Age biasanya memiliki importance tertinggi\n",
    "- Make_Encoded penting untuk membedakan brand luxury vs economy\n",
    "- State_Encoded menangkap perbedaan harga regional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841365b",
   "metadata": {},
   "source": [
    "## 4. Model Training & Comparison\n",
    "\n",
    "\n",
    "\n",
    "**Strategi:**- **RMSE (Root Mean Squared Error):** Penalti lebih besar untuk error yang besar (semakin rendah semakin baik)\n",
    "\n",
    "- Membandingkan 2 model: Simple (2 fitur) vs Full (4 fitur)- **MAE (Mean Absolute Error):** Rata-rata kesalahan prediksi dalam dollar (semakin rendah semakin baik)\n",
    "\n",
    "- Menggunakan Random Forest Regressor- **R¬≤ Score:** Seberapa baik model menjelaskan variance harga (0-1, semakin tinggi semakin baik)\n",
    "\n",
    "- Train-Test Split: 80% training, 20% testing**Metrics:**\n",
    "\n",
    "- Random state = 42 untuk reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbf7a3",
   "metadata": {},
   "source": [
    "### 4.1 Model Comparison: Simple vs Full Features\n",
    "\n",
    "**Full Model:** Menggunakan Car_Age, Mileage, Make_Encoded, dan State_Encoded\n",
    "**Simple Model:** Hanya menggunakan Car_Age dan Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MODEL COMPARISON: SIMPLE vs FULL FEATURES\")\n",
    "print(\"\\nSIMPLE MODEL\")\n",
    "print(\"Features: Car_Age, Mileage only\\n\")\n",
    "\n",
    "simple_features = ['Car_Age', 'Mileage']\n",
    "X_simple = df_clean[simple_features]\n",
    "y_simple = df_clean['Price']\n",
    "\n",
    "# Split and train simple model\n",
    "X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(\n",
    "    X_simple, y_simple, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model_simple = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_simple.fit(X_train_simple, y_train_simple)\n",
    "y_pred_simple = model_simple.predict(X_test_simple)\n",
    "\n",
    "# Metrics for simple model\n",
    "r2_simple = r2_score(y_test_simple, y_pred_simple)\n",
    "mae_simple = mean_absolute_error(y_test_simple, y_pred_simple)\n",
    "rmse_simple = np.sqrt(mean_squared_error(y_test_simple, y_pred_simple))\n",
    "\n",
    "print(f\"R¬≤ Score: {r2_simple:.4f} ({r2_simple*100:.2f}%)\")\n",
    "print(f\"MAE: ${mae_simple:,.2f}\")\n",
    "print(f\"RMSE: ${rmse_simple:,.2f}\")\n",
    "print(f\"Number of features: {len(simple_features)}\")\n",
    "\n",
    "print(\"\\nFULL FEATURE MODEL\")\n",
    "print(\"Features: Mileage, Car_Age, Make, State (no Model_Frequency)\\n\")\n",
    "\n",
    "full_features = ['Mileage', 'Car_Age', 'Make_Encoded', 'State_Encoded']\n",
    "X_full = df_clean[full_features]\n",
    "y_full = df_clean['Price']\n",
    "\n",
    "# Split data\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train full model with Random Forest\n",
    "model_full = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_full.fit(X_train_full, y_train_full)\n",
    "y_pred_full = model_full.predict(X_test_full)\n",
    "\n",
    "# Metrics for full model\n",
    "r2_full = r2_score(y_test_full, y_pred_full)\n",
    "mae_full = mean_absolute_error(y_test_full, y_pred_full)\n",
    "rmse_full = np.sqrt(mean_squared_error(y_test_full, y_pred_full))\n",
    "\n",
    "print(f\"R¬≤ Score: {r2_full:.4f} ({r2_full*100:.2f}%)\")\n",
    "print(f\"MAE: ${mae_full:,.2f}\")\n",
    "print(f\"RMSE: ${rmse_full:,.2f}\")\n",
    "print(f\"Number of features: {len(full_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6368f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON ANALYSIS\n",
    "print(\"üìà COMPARISON ANALYSIS\")\n",
    "\n",
    "print(f\"\\nüéØ R¬≤ Score Improvement:\")\n",
    "r2_improvement = ((r2_full - r2_simple) / r2_simple) * 100\n",
    "print(f\"   Simple Model: {r2_simple:.4f} ({r2_simple*100:.2f}%)\")\n",
    "print(f\"   Full Model:   {r2_full:.4f} ({r2_full*100:.2f}%)\")\n",
    "print(f\"   Improvement:  {r2_improvement:+.2f}% ({abs(r2_full - r2_simple):.4f} increase)\")\n",
    "\n",
    "print(f\"\\nüí∞ MAE Improvement:\")\n",
    "mae_improvement = ((mae_simple - mae_full) / mae_simple) * 100\n",
    "print(f\"   Simple Model: ${mae_simple:,.2f}\")\n",
    "print(f\"   Full Model:   ${mae_full:,.2f}\")\n",
    "print(f\"   Improvement:  {mae_improvement:+.2f}% (${abs(mae_simple - mae_full):,.2f} reduction)\")\n",
    "\n",
    "print(f\"\\nüìâ RMSE Improvement:\")\n",
    "rmse_improvement = ((rmse_simple - rmse_full) / rmse_simple) * 100\n",
    "print(f\"   Simple Model: ${rmse_simple:,.2f}\")\n",
    "print(f\"   Full Model:   ${rmse_full:,.2f}\")\n",
    "print(f\"   Improvement:  {rmse_improvement:+.2f}% (${abs(rmse_simple - rmse_full):,.2f} reduction)\")\n",
    "\n",
    "\n",
    "if r2_full > r2_simple and mae_full < mae_simple:\n",
    "    print(\"\\n‚úÖ USE FULL FEATURE MODEL\")\n",
    "    print(\"\\nReasons:\")\n",
    "    print(f\"   ‚Ä¢ {r2_improvement:.1f}% better at explaining price variance\")\n",
    "    print(f\"   ‚Ä¢ ${abs(mae_simple - mae_full):,.2f} lower average prediction error\")\n",
    "    print(f\"   ‚Ä¢ More accurate predictions for both buyers and sellers\")\n",
    "    print(f\"   ‚Ä¢ Captures important factors: brand, location, and model popularity\")\n",
    "    print(\"\\n   The additional features significantly improve prediction accuracy,\")\n",
    "    print(\"   making it worth the added complexity.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ USE SIMPLE MODEL\")\n",
    "    print(\"\\nReasons:\")\n",
    "    print(f\"   ‚Ä¢ Simpler and easier to interpret\")\n",
    "    print(f\"   ‚Ä¢ Fewer data requirements\")\n",
    "    print(f\"   ‚Ä¢ Minimal performance difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Comparison of Models\n",
    "print(\"üìä VISUAL COMPARISON\\n\")\n",
    "\n",
    "# Comparison Bar Chart\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# R¬≤ Score Comparison\n",
    "models = ['Simple\\nModel', 'Full Feature\\nModel']\n",
    "r2_scores = [r2_simple, r2_full]\n",
    "colors_r2 = ['skyblue', 'green' if r2_full > r2_simple else 'orange']\n",
    "\n",
    "axes[0].bar(models, r2_scores, color=colors_r2, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_ylabel('R¬≤ Score', fontsize=12)\n",
    "axes[0].set_title('R¬≤ Score Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(r2_scores):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.4f}\\n({v*100:.2f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "# MAE Comparison (lower is better)\n",
    "mae_scores = [mae_simple, mae_full]\n",
    "colors_mae = ['skyblue', 'green' if mae_full < mae_simple else 'orange']\n",
    "\n",
    "axes[1].bar(models, mae_scores, color=colors_mae, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_ylabel('MAE ($)', fontsize=12)\n",
    "axes[1].set_title('Mean Absolute Error (Lower is Better)', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(mae_scores):\n",
    "    axes[1].text(i, v + max(mae_scores)*0.02, f'${v:,.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# RMSE Comparison (lower is better)\n",
    "rmse_scores = [rmse_simple, rmse_full]\n",
    "colors_rmse = ['skyblue', 'green' if rmse_full < rmse_simple else 'orange']\n",
    "\n",
    "axes[2].bar(models, rmse_scores, color=colors_rmse, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[2].set_ylabel('RMSE ($)', fontsize=12)\n",
    "axes[2].set_title('Root Mean Squared Error (Lower is Better)', fontsize=13, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(rmse_scores):\n",
    "    axes[2].text(i, v + max(rmse_scores)*0.02, f'${v:,.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prediction Comparison Scatter Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Simple Model Predictions\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_simple, y_pred_simple, alpha=0.4, color='skyblue', s=15, edgecolors='black', linewidth=0.3)\n",
    "plt.plot([y_test_simple.min(), y_test_simple.max()], \n",
    "         [y_test_simple.min(), y_test_simple.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Price ($)', fontsize=11)\n",
    "plt.ylabel('Predicted Price ($)', fontsize=11)\n",
    "plt.title('Simple Model: Actual vs Predicted', fontsize=13, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.text(0.05, 0.95, f'R¬≤ = {r2_simple:.4f}\\nMAE = ${mae_simple:,.0f}', \n",
    "         transform=plt.gca().transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "# Full Model Predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test_full, y_pred_full, alpha=0.4, color='green', s=15, edgecolors='black', linewidth=0.3)\n",
    "plt.plot([y_test_full.min(), y_test_full.max()], \n",
    "         [y_test_full.min(), y_test_full.max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Price ($)', fontsize=11)\n",
    "plt.ylabel('Predicted Price ($)', fontsize=11)\n",
    "plt.title('Full Feature Model: Actual vs Predicted', fontsize=13, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.text(0.05, 0.95, f'R¬≤ = {r2_full:.4f}\\nMAE = ${mae_full:,.0f}', \n",
    "         transform=plt.gca().transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visual comparison complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a3cea",
   "metadata": {},
   "source": [
    "## 5. Final Model Selection\n",
    "\n",
    "### 5.1 Feature Selection Decision\n",
    "\n",
    "**Final Features:** Mileage, Car_Age, Make_Encoded, State_Encoded\n",
    "\n",
    "**‚úÖ Make_Encoded Dipertahankan (Meskipun Korelasi Rendah):**\n",
    "- Korelasi rendah ‚â† Importance rendah untuk categorical variables di tree-based models\n",
    "- Make_Encoded: korelasi -0.06 tapi importance 29% (rasio: 4.95x)\n",
    "- **Alasan:** LabelEncoder memberikan angka arbitrary (Ferrari=13, McLaren=37, Saturn=49)\n",
    "- Angka-angka ini tidak memiliki urutan bermakna, jadi korelasi linear rendah adalah **EXPECTED**\n",
    "- Random Forest tidak bergantung pada hubungan linear - ia membuat categorical splits\n",
    "- **Contoh:** RF belajar \"If Make=13 (Ferrari) ‚Üí High Price\" vs \"If Make=49 (Saturn) ‚Üí Low Price\"\n",
    "- **Brand sangat penting untuk pricing:** Ferrari akan selalu lebih mahal dari Ford, apapun encodingnya\n",
    "- **Kesimpulan:** Make_Encoded menangkap informasi brand yang esensial untuk prediksi harga\n",
    "\n",
    "**‚ùå Model_Frequency Dihapus:**\n",
    "- Importance 34.3% tapi korelasi hanya +0.08 (rasio: 4.20x)\n",
    "- Ini menunjukkan **overfitting ke noise** bukan pola harga sebenarnya\n",
    "- Model populer ‚â† Model mahal (contoh: Honda Civic sangat umum tapi terjangkau)\n",
    "- Model langka ‚â† Model mahal (contoh: model Saturn yang discontinued: langka tapi murah)\n",
    "- Feature ini menangkap korelasi palsu dalam training data\n",
    "- **Kesimpulan:** Menghapusnya meningkatkan generalisasi model dan mengurangi overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model: Random Forest with Best Features (CORRECTED)\n",
    "print(\"=== FINAL MODEL SELECTION (CORRECTED) ===\\n\")\n",
    "\n",
    "# Removed Model_Frequency due to overfitting (high importance but low correlation)\n",
    "# Kept Make_Encoded despite low correlation (expected for categorical features)\n",
    "features = ['Mileage', 'Car_Age', 'Make_Encoded', 'State_Encoded']\n",
    "X = df_clean[features]\n",
    "y = df_clean['Price']\n",
    "\n",
    "print(f\"‚úì Features: {', '.join(features)}\")\n",
    "print(f\"‚úì Removed: Model_Frequency (overfitting to noise)\")\n",
    "print(f\"‚úì Kept: Make_Encoded (brand is crucial, low corr is expected)\")\n",
    "\n",
    "# Split and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n‚úì Training: {X_train.shape[0]:,} samples | Testing: {X_test.shape[0]:,} samples\")\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(f\"‚úì Random Forest trained (100 trees, max_depth=20)\")\n",
    "\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9f4f3",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation & Performance Metrics\n",
    "\n",
    "### 6.1 Performance Metrics\n",
    "\n",
    "**Evaluasi performa model final:**\n",
    "\n",
    "- Membandingkan metrics pada training set vs testing set- Menganalisis feature importance\n",
    "- Melihat apakah ada overfitting (training score >> testing score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b7fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"\\nüìä TRAINING:   R¬≤={r2_train:.4f} | MAE=${mae_train:,.0f} | RMSE=${rmse_train:,.0f}\")\n",
    "print(f\"üìä TESTING:    R¬≤={r2_test:.4f} | MAE=${mae_test:,.0f} | RMSE=${rmse_test:,.0f}\")\n",
    "print(f\"\\nüí° Model explains {r2_test*100:.1f}% of price variance\")\n",
    "print(f\"üí° Average prediction error: ${mae_test:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedeef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance DataFrame\n",
    "feature_importance = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importance,\n",
    "    'Importance_Percent': feature_importance * 100\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Check actual feature importance ranking\n",
    "print(\"=== ACTUAL FEATURE IMPORTANCE ===\\n\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Visualize with percentages\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(importance_df['Feature'], importance_df['Importance_Percent'])\n",
    "plt.xlabel('Importance (%)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance from Random Forest', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add percentage labels\n",
    "for i, (feature, importance) in enumerate(zip(importance_df['Feature'], importance_df['Importance_Percent'])):\n",
    "    plt.text(importance + 1, i, f'{importance:.1f}%', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: [cars.ipynb](http://_vscodecontentref_/0)\n",
    "# Performance Metrics\n",
    "print(\"=== MODEL PERFORMANCE EVALUATION ===\\n\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"üìä TRAINING SET:\")\n",
    "print(f\"   R¬≤ Score: {r2_train:.4f} ({r2_train*100:.2f}%)\")\n",
    "print(f\"   MAE: ${mae_train:,.2f}\")\n",
    "print(f\"   RMSE: ${rmse_train:,.2f}\")\n",
    "\n",
    "print(f\"\\nüìä TESTING SET:\")\n",
    "print(f\"   R¬≤ Score: {r2_test:.4f} ({r2_test*100:.2f}%)\")\n",
    "print(f\"   MAE: ${mae_test:,.2f}\")\n",
    "print(f\"   RMSE: ${rmse_test:,.2f}\")\n",
    "\n",
    "# Overfitting Analysis\n",
    "print(f\"\\nüîç OVERFITTING ANALYSIS:\")\n",
    "print(\"-\" * 60)\n",
    "r2_diff = r2_train - r2_test\n",
    "mae_diff_pct = ((mae_test - mae_train) / mae_train) * 100\n",
    "rmse_diff_pct = ((rmse_test - rmse_train) / rmse_train) * 100\n",
    "\n",
    "print(f\"R¬≤ Difference: {r2_diff:.4f} ({r2_diff*100:.2f}%)\")\n",
    "print(f\"MAE Increase: {mae_diff_pct:+.2f}%\")\n",
    "print(f\"RMSE Increase: {rmse_diff_pct:+.2f}%\")\n",
    "\n",
    "# Interpretation\n",
    "if r2_diff < 0.05 and mae_diff_pct < 10:\n",
    "    print(f\"\\n‚úÖ MODEL STATUS: GOOD FIT (No Overfitting)\")\n",
    "    print(f\"   ‚Ä¢ Training dan Testing performance sangat dekat\")\n",
    "    print(f\"   ‚Ä¢ Model dapat generalisasi dengan baik ke data baru\")\n",
    "    print(f\"   ‚Ä¢ R¬≤ difference hanya {r2_diff:.4f} (< 0.05 threshold)\")\n",
    "    print(f\"   ‚Ä¢ MAE increase hanya {mae_diff_pct:.1f}% (< 10% threshold)\")\n",
    "elif r2_diff < 0.10 and mae_diff_pct < 20:\n",
    "    print(f\"\\n‚ö†Ô∏è MODEL STATUS: SLIGHT OVERFITTING\")\n",
    "    print(f\"   ‚Ä¢ Ada sedikit perbedaan antara training dan testing\")\n",
    "    print(f\"   ‚Ä¢ Model masih dapat digunakan, tapi bisa ditingkatkan\")\n",
    "    print(f\"   ‚Ä¢ Pertimbangkan: tambah data, kurangi max_depth, atau feature selection\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå MODEL STATUS: OVERFITTING DETECTED\")\n",
    "    print(f\"   ‚Ä¢ Training performance jauh lebih baik dari testing\")\n",
    "    print(f\"   ‚Ä¢ Model terlalu 'hafal' data training\")\n",
    "    print(f\"   ‚Ä¢ Solusi: simplify model, regularization, atau tambah data\")\n",
    "\n",
    "print(f\"\\nüí° INSIGHTS:\")\n",
    "print(f\"   ‚Ä¢ Model menjelaskan {r2_test*100:.1f}% variance harga pada data testing\")\n",
    "print(f\"   ‚Ä¢ Rata-rata error prediksi: ${mae_test:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Prediksi cukup akurat untuk aplikasi real-world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bc1ee",
   "metadata": {},
   "source": [
    "## 7. Strategi Mengatasi Overfitting (Jika Diperlukan)\n",
    "\n",
    "**Jika model menunjukkan overfitting, gunakan strategi berikut:**\n",
    "\n",
    "### Teknik Anti-Overfitting:\n",
    "\n",
    "1. **Hyperparameter Tuning**\n",
    "   - Kurangi `max_depth` (dari 20 ke 10-15)\n",
    "   - Tambahkan `min_samples_split` dan `min_samples_leaf`\n",
    "   - Gunakan `max_features='sqrt'` untuk mengurangi fitur per tree\n",
    "\n",
    "2. **Cross-Validation**\n",
    "   - Validasi model dengan 5-Fold CV untuk hasil yang lebih robust\n",
    "   - Memastikan model konsisten di berbagai data splits\n",
    "\n",
    "3. **Feature Selection**\n",
    "   - Hapus fitur dengan importance rendah (< 10%)\n",
    "   - Fokus pada fitur yang paling informatif\n",
    "\n",
    "4. **Regularization**\n",
    "   - Tambah lebih banyak data training\n",
    "   - Gunakan ensemble methods dengan diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb6907",
   "metadata": {},
   "source": [
    "### 7.1 Hyperparameter Tuning\n",
    "\n",
    "**Mencoba berbagai kombinasi hyperparameters untuk menemukan yang terbaik:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef80579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 1: Hyperparameter Tuning to Reduce Overfitting\n",
    "print(\"=== STRATEGY 1: HYPERPARAMETER TUNING ===\\n\")\n",
    "\n",
    "# Try different max_depth values\n",
    "max_depths = [10, 15, 20, None]\n",
    "results = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    model_tuned = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=depth,\n",
    "        min_samples_split=10,      # Require more samples to split\n",
    "        min_samples_leaf=5,         # Require more samples in leaf nodes\n",
    "        max_features='sqrt',        # Use fewer features per tree\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model_tuned.fit(X_train, y_train)\n",
    "    y_train_pred_tuned = model_tuned.predict(X_train)\n",
    "    y_test_pred_tuned = model_tuned.predict(X_test)\n",
    "    \n",
    "    r2_train_tuned = r2_score(y_train, y_train_pred_tuned)\n",
    "    r2_test_tuned = r2_score(y_test, y_test_pred_tuned)\n",
    "    mae_test_tuned = mean_absolute_error(y_test, y_test_pred_tuned)\n",
    "    \n",
    "    results.append({\n",
    "        'max_depth': depth if depth else 'None',\n",
    "        'r2_train': r2_train_tuned,\n",
    "        'r2_test': r2_test_tuned,\n",
    "        'r2_diff': r2_train_tuned - r2_test_tuned,\n",
    "        'mae_test': mae_test_tuned\n",
    "    })\n",
    "    \n",
    "    print(f\"max_depth={depth}: R¬≤_train={r2_train_tuned:.4f}, R¬≤_test={r2_test_tuned:.4f}, Diff={r2_train_tuned-r2_test_tuned:.4f}\")\n",
    "\n",
    "# Find best model\n",
    "results_df = pd.DataFrame(results)\n",
    "best_idx = results_df['r2_diff'].idxmin()\n",
    "best_params = results_df.iloc[best_idx]\n",
    "\n",
    "print(f\"\\n‚úÖ BEST MODEL:\")\n",
    "print(f\"   max_depth: {best_params['max_depth']}\")\n",
    "print(f\"   R¬≤ Test: {best_params['r2_test']:.4f}\")\n",
    "print(f\"   MAE Test: ${best_params['mae_test']:,.0f}\")\n",
    "print(f\"   Overfitting Gap: {best_params['r2_diff']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a14bfb",
   "metadata": {},
   "source": [
    "### 7.2 Cross-Validation\n",
    "\n",
    "**Validasi model dengan 5-Fold Cross-Validation untuk memastikan konsistensi:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76342068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 2: Cross-Validation\n",
    "print(\"\\n=== STRATEGY 2: CROSS-VALIDATION ===\\n\")\n",
    "\n",
    "# Use best hyperparameters from tuning\n",
    "best_depth = int(best_params['max_depth']) if best_params['max_depth'] != 'None' else None\n",
    "\n",
    "model_cv = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=best_depth,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "print(\"Running 5-Fold Cross-Validation...\")\n",
    "cv_scores = cross_val_score(model_cv, X, y, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(f\"\\nCross-Validation R¬≤ Scores:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"   Fold {i}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nMean R¬≤: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
    "print(f\"Min R¬≤: {cv_scores.min():.4f}\")\n",
    "print(f\"Max R¬≤: {cv_scores.max():.4f}\")\n",
    "\n",
    "if cv_scores.std() < 0.02:\n",
    "    print(f\"\\n‚úÖ Model sangat konsisten across different data splits\")\n",
    "elif cv_scores.std() < 0.05:\n",
    "    print(f\"\\n‚úì Model cukup konsisten across different data splits\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Model kurang konsisten, pertimbangkan untuk tambah data atau simplify model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a6f42",
   "metadata": {},
   "source": [
    "### 7.3 Feature Selection\n",
    "\n",
    "**Menghapus fitur dengan importance rendah untuk simplify model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc21db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 3: Feature Selection Based on Importance\n",
    "print(\"\\n=== STRATEGY 3: FEATURE SELECTION ===\\n\")\n",
    "\n",
    "# Train model to get feature importance\n",
    "model_temp = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    random_state=42, \n",
    "    max_depth=best_depth,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5\n",
    ")\n",
    "model_temp.fit(X_train, y_train)\n",
    "\n",
    "# Analyze feature importance\n",
    "importance_threshold = 0.10\n",
    "feature_importance_temp = model_temp.feature_importances_\n",
    "feature_imp_dict = dict(zip(features, feature_importance_temp))\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for feat, imp in sorted(feature_imp_dict.items(), key=lambda x: x[1], reverse=True):\n",
    "    status = \"‚úì Keep\" if imp >= importance_threshold else \"‚úó Remove\"\n",
    "    print(f\"   {feat:20s}: {imp:.4f} ({imp*100:.1f}%) - {status}\")\n",
    "\n",
    "# Keep only important features\n",
    "important_features = [f for f, imp in zip(features, feature_importance_temp) if imp >= importance_threshold]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Original features ({len(features)}): {features}\")\n",
    "print(f\"Selected features ({len(important_features)}): {important_features}\")\n",
    "print(f\"Removed: {set(features) - set(important_features)}\")\n",
    "\n",
    "# Only proceed if we actually removed features\n",
    "if len(important_features) < len(features):\n",
    "    # Retrain with selected features\n",
    "    X_selected = df_clean[important_features]\n",
    "    X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(\n",
    "        X_selected, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model_selected = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=best_depth,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model_selected.fit(X_train_sel, y_train_sel)\n",
    "\n",
    "    r2_train_sel = r2_score(y_train_sel, model_selected.predict(X_train_sel))\n",
    "    r2_test_sel = r2_score(y_test_sel, model_selected.predict(X_test_sel))\n",
    "    mae_test_sel = mean_absolute_error(y_test_sel, model_selected.predict(X_test_sel))\n",
    "\n",
    "    print(f\"\\nüìä FEATURE SELECTED MODEL PERFORMANCE:\")\n",
    "    print(f\"   R¬≤ Train: {r2_train_sel:.4f}\")\n",
    "    print(f\"   R¬≤ Test: {r2_test_sel:.4f}\")\n",
    "    print(f\"   MAE Test: ${mae_test_sel:,.0f}\")\n",
    "    print(f\"   Overfitting Gap: {r2_train_sel - r2_test_sel:.4f}\")\n",
    "else:\n",
    "    print(f\"\\n‚úì All features are important (>{importance_threshold*100}%), no removal needed\")\n",
    "    r2_train_sel = r2_train\n",
    "    r2_test_sel = r2_test\n",
    "    mae_test_sel = mae_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea0c91",
   "metadata": {},
   "source": [
    "### 7.4 Final Comparison: Semua Strategi\n",
    "\n",
    "**Membandingkan performa semua model untuk memilih yang terbaik:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRATEGY 4: Visual Comparison of All Approaches\n",
    "print(\"\\n=== FINAL COMPARISON: ALL STRATEGIES ===\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prepare comparison data\n",
    "models_comparison = ['Original\\n(max_depth=20)', f'Tuned\\n(max_depth={best_params[\"max_depth\"]})', 'Cross-\\nValidated', 'Feature\\nSelected']\n",
    "train_scores = [r2_train, best_params['r2_train'], cv_scores.mean(), r2_train_sel]\n",
    "test_scores = [r2_test, best_params['r2_test'], cv_scores.mean(), r2_test_sel]\n",
    "\n",
    "x = np.arange(len(models_comparison))\n",
    "width = 0.35\n",
    "\n",
    "# Plot 1: Training vs Testing R¬≤ Scores\n",
    "bars1 = axes[0].bar(x - width/2, train_scores, width, label='Training', color='skyblue', edgecolor='black', linewidth=1.5)\n",
    "bars2 = axes[0].bar(x + width/2, test_scores, width, label='Testing', color='green', edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_ylabel('R¬≤ Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Model Comparison: Training vs Testing R¬≤', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models_comparison, fontsize=10)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].set_ylim([0.8, 1.0])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (train, test) in enumerate(zip(train_scores, test_scores)):\n",
    "    axes[0].text(i - width/2, train + 0.01, f'{train:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "    axes[0].text(i + width/2, test + 0.01, f'{test:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot 2: Overfitting Gap (Train - Test)\n",
    "gaps = [abs(t - te) for t, te in zip(train_scores, test_scores)]\n",
    "colors = ['red' if g > 0.05 else 'orange' if g > 0.03 else 'green' for g in gaps]\n",
    "\n",
    "bars = axes[1].bar(models_comparison, gaps, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "axes[1].axhline(y=0.05, color='red', linestyle='--', linewidth=2, label='High Overfitting (>0.05)')\n",
    "axes[1].axhline(y=0.03, color='orange', linestyle='--', linewidth=2, label='Slight Overfitting (>0.03)')\n",
    "axes[1].set_ylabel('R¬≤ Difference (Train - Test)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Overfitting Gap Analysis', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(fontsize=9, loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].set_ylim([0, max(gaps) * 1.2])\n",
    "\n",
    "# Add value labels\n",
    "for i, gap in enumerate(gaps):\n",
    "    axes[1].text(i, gap + max(gaps)*0.02, f'{gap:.4f}', ha='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä PERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<25} {'R¬≤ Train':>10} {'R¬≤ Test':>10} {'Gap':>10} {'MAE Test':>15}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Original (max_depth=20)':<25} {r2_train:>10.4f} {r2_test:>10.4f} {r2_train-r2_test:>10.4f} ${mae_test:>14,.0f}\")\n",
    "print(f\"{'Tuned (best params)':<25} {best_params['r2_train']:>10.4f} {best_params['r2_test']:>10.4f} {best_params['r2_diff']:>10.4f} ${best_params['mae_test']:>14,.0f}\")\n",
    "print(f\"{'Cross-Validated':<25} {cv_scores.mean():>10.4f} {cv_scores.mean():>10.4f} {0:>10.4f} {'N/A':>15}\")\n",
    "print(f\"{'Feature Selected':<25} {r2_train_sel:>10.4f} {r2_test_sel:>10.4f} {r2_train_sel-r2_test_sel:>10.4f} ${mae_test_sel:>14,.0f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Recommendation\n",
    "best_gap = min(gaps)\n",
    "best_r2 = max(test_scores)\n",
    "best_model_idx = gaps.index(best_gap)\n",
    "\n",
    "print(f\"\\n‚úÖ RECOMMENDATION:\")\n",
    "print(f\"   Model terbaik: {models_comparison[best_model_idx].replace(chr(10), ' ')}\")\n",
    "print(f\"   ‚Ä¢ Lowest overfitting gap: {best_gap:.4f}\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Test: {test_scores[best_model_idx]:.4f}\")\n",
    "print(f\"   ‚Ä¢ Model ini memiliki keseimbangan terbaik antara performance dan generalization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
